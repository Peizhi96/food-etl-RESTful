# Starter pipeline
# Start with a minimal pipeline that you can customize to build and deploy your code.
# Add steps that build, run tests, deploy, and more:
# https://aka.ms/yaml

trigger:
- main

pool:
  vmImage: ubuntu-latest

steps:
- checkout: self

- task: UsePythonVersion@0
  inputs:
    versionSpec: '3.x'

- script: |
    # Install necessary Python packages
    pip install -r requirements.txt
    pip install pytest sqlalchemy==2.0.12
    pip install databricks-cli
  displayName: 'Install dependencies and Databricks CLI'

- script: |
    databricks configure --token --host https://adb-750644874697514.14.azuredatabricks.net/
    databricks workspace import_dir /Users/Peizhi/Desktop/Main/DE/data-engineer/food-etl-RESTful /Shared --overwrite
  displayName: 'Deploy Notebooks to Databricks'
  env:
    DATABRICKS_TOKEN: $(DATABRICKS_PAT)
