# Starter pipeline
# Start with a minimal pipeline that you can customize to build and deploy your code.
# Add steps that build, run tests, deploy, and more:
# https://aka.ms/yaml

trigger:
- main

pool:
  vmImage: ubuntu-latest

steps:
- checkout: self

- script: |
    sudo apt-get update
    sudo apt-get install -y unixodbc-dev libpq-dev
  displayName: 'Install system dependencies'

- task: UsePythonVersion@0
  inputs:
    versionSpec: '3.x'
- script: |
    pip install -r requirements.txt
    pip install databricks-cli
  displayName: 'Install Python dependencies'

- script: |
    export DATABRICKS_HOST=https://adb-750644874697514.14.azuredatabricks.net
    export DATABRICKS_TOKEN=$DATABRICKS_PAT

    echo "Listing contents of current directory:"
    ls -la
    
    databricks workspace import_dir /restaurant.ipynb /Shared/restaurant.ipynb --overwrite
  displayName: 'Deploy Notebooks to Databricks'
  env:
    DATABRICKS_PAT: $(DATABRICKS_PAT)
